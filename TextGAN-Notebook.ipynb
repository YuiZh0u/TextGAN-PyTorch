{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Discrete GANs",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqKnoudCIRLt"
      },
      "source": [
        "# TextGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utcwGr26HY9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7ea20e-b49b-4f08-b9b5-da06dff55b45"
      },
      "source": [
        "#Solo si se está usando Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stnf2wNjBEmc"
      },
      "source": [
        "#Solo si se está usando Google Colab\n",
        "#Solo ejecutar una vez, es para clonar el repo en drive (para tener las salidas generadas guardadas en el drive en caso de que se apague la maquina).\n",
        "!cd /content/gdrive/MyDrive && git clone -b Thesis https://github.com/YuiZh0u/TextGAN-PyTorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJWHBqMSDFD3"
      },
      "source": [
        "## Instalación de requisitos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGJm75BcCMDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0994661-7aad-4510-fc57-8aa6df8d3eff"
      },
      "source": [
        "!cd /content/gdrive/MyDrive/TextGAN-PyTorch && pip install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.9.0+cu102)\n",
            "Collecting nltk>=3.4.5\n",
            "  Downloading nltk-3.6.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->-r requirements.txt (line 2)) (4.62.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->-r requirements.txt (line 2)) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->-r requirements.txt (line 2)) (1.0.1)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5hx8DyiCfRu"
      },
      "source": [
        "!apt-get install libboost-all-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOWD0lNvBaQp"
      },
      "source": [
        "!git clone https://github.com/kpu/kenlm.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EySEq8gCqcy"
      },
      "source": [
        "!cd kenlm && mkdir -p build && cd build && cmake .. && make -j 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NVZl9AaA8ve",
        "outputId": "6b4dc1ec-435a-48ff-f51e-5877c3c58187"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUcuCCxa1NXj"
      },
      "source": [
        "# !cp /content/gdrive/MyDrive/word2vec/covid_tweets_equal16.txt /content/gdrive/MyDrive/TextGAN-PyTorch/dataset/testdata/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtGK6GUHC71E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a4ecd8-1e4b-484e-8605-0545dd1fa7eb"
      },
      "source": [
        "!cd /content/gdrive/MyDrive/TextGAN-PyTorch/run && python3 run_seqgan.py 3 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "job_id: 3, gpu_id: 0\n",
            "total tokens:  32666\n",
            "====================================================================================================\n",
            "> training arguments:\n",
            ">>> if_test: 0\n",
            ">>> run_model: seqgan\n",
            ">>> k_label: 2\n",
            ">>> dataset: covid_tweets\n",
            ">>> model_type: vanilla\n",
            ">>> loss_type: rsgan\n",
            ">>> mu_type: ragan\n",
            ">>> eval_type: Ra\n",
            ">>> d_type: Ra\n",
            ">>> if_real_data: 1\n",
            ">>> cuda: 1\n",
            ">>> device: 0\n",
            ">>> devices: 0\n",
            ">>> shuffle: 0\n",
            ">>> gen_init: normal\n",
            ">>> dis_init: uniform\n",
            ">>> n_parent: 1\n",
            ">>> eval_b_num: 8\n",
            ">>> lambda_fq: 1.0\n",
            ">>> lambda_fd: 0.0\n",
            ">>> d_out_mean: True\n",
            ">>> freeze_dis: False\n",
            ">>> freeze_clas: False\n",
            ">>> use_all_real_fake: False\n",
            ">>> use_population: False\n",
            ">>> samples_num: 10000\n",
            ">>> vocab_size: 32666\n",
            ">>> mle_epoch: 120\n",
            ">>> clas_pre_epoch: 10\n",
            ">>> adv_epoch: 200\n",
            ">>> inter_epoch: 15\n",
            ">>> batch_size: 64\n",
            ">>> max_seq_len: 66\n",
            ">>> start_letter: 1\n",
            ">>> padding_idx: 0\n",
            ">>> gen_lr: 0.01\n",
            ">>> gen_adv_lr: 0.0001\n",
            ">>> dis_lr: 0.0001\n",
            ">>> clip_norm: 5.0\n",
            ">>> pre_log_step: 10\n",
            ">>> adv_log_step: 1\n",
            ">>> train_data: dataset/covid_tweets.txt\n",
            ">>> test_data: dataset/testdata/covid_tweets_test.txt\n",
            ">>> temp_adpt: exp\n",
            ">>> evo_temp_step: 1\n",
            ">>> temperature: 1\n",
            ">>> ora_pretrain: 1\n",
            ">>> gen_pretrain: 0\n",
            ">>> dis_pretrain: 0\n",
            ">>> adv_g_step: 1\n",
            ">>> rollout_num: 16\n",
            ">>> gen_embed_dim: 32\n",
            ">>> gen_hidden_dim: 32\n",
            ">>> goal_size: 16\n",
            ">>> step_size: 4\n",
            ">>> mem_slots: 1\n",
            ">>> num_heads: 2\n",
            ">>> head_size: 256\n",
            ">>> d_step: 5\n",
            ">>> d_epoch: 3\n",
            ">>> adv_d_step: 4\n",
            ">>> adv_d_epoch: 2\n",
            ">>> dis_embed_dim: 64\n",
            ">>> dis_hidden_dim: 64\n",
            ">>> num_rep: 64\n",
            ">>> use_nll_oracle: 1\n",
            ">>> use_nll_gen: 1\n",
            ">>> use_nll_div: 1\n",
            ">>> use_bleu: 1\n",
            ">>> use_self_bleu: 1\n",
            ">>> use_clas_acc: True\n",
            ">>> use_ppl: 0\n",
            ">>> log_file: log/log_0928_1619_45.txt\n",
            ">>> save_root: save/20210928/covid_tweets/seqgan_vanilla_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl66_temp1_lfd0.0_T0928_1619_45/\n",
            ">>> signal_file: run_signal.txt\n",
            ">>> tips: SeqGAN experiments\n",
            "====================================================================================================\n",
            "Starting Generator MLE Training...\n",
            "[MLE-GEN] epoch 0 : pre_loss = 2.7074, BLEU-[2, 3, 4, 5] = [0.514, 0.241, 0.099, 0.051], NLL_gen = 2.3577, NLL_div = 2.4687, Self-BLEU-[2, 3, 4] = [0.691, 0.38, 0.177], [PPL-F, PPL-R] = 0\n",
            "[MLE-GEN] epoch 10 : pre_loss = 2.0329, BLEU-[2, 3, 4, 5] = [0.703, 0.386, 0.177, 0.091], NLL_gen = 2.0415, NLL_div = 2.2931, Self-BLEU-[2, 3, 4] = [0.786, 0.469, 0.225], [PPL-F, PPL-R] = 0\n",
            "[MLE-GEN] epoch 20 : pre_loss = 1.9974, BLEU-[2, 3, 4, 5] = [0.698, 0.376, 0.168, 0.084], NLL_gen = 2.0161, NLL_div = 2.2386, Self-BLEU-[2, 3, 4] = [0.783, 0.468, 0.218], [PPL-F, PPL-R] = 0\n",
            "[MLE-GEN] epoch 30 : pre_loss = 1.9828, BLEU-[2, 3, 4, 5] = [0.698, 0.387, 0.175, 0.088], NLL_gen = 2.0122, NLL_div = 2.3113, Self-BLEU-[2, 3, 4] = [0.79, 0.466, 0.224], [PPL-F, PPL-R] = 0\n",
            "[MLE-GEN] epoch 40 : pre_loss = 1.9745, BLEU-[2, 3, 4, 5] = [0.725, 0.399, 0.174, 0.086], NLL_gen = 2.0052, NLL_div = 2.2641, Self-BLEU-[2, 3, 4] = [0.791, 0.469, 0.225], [PPL-F, PPL-R] = 0\n"
          ]
        }
      ]
    }
  ]
}