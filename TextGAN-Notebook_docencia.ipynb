{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqKnoudCIRLt"
   },
   "source": [
    "# TextGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utcwGr26HY9h",
    "outputId": "8b7ea20e-b49b-4f08-b9b5-da06dff55b45"
   },
   "outputs": [],
   "source": [
    "#Solo si se está usando Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Stnf2wNjBEmc"
   },
   "outputs": [],
   "source": [
    "#Solo si se está usando Google Colab\n",
    "#Solo ejecutar una vez, es para clonar el repo en drive (para tener las salidas generadas guardadas en el drive en caso de que se apague la maquina).\n",
    "!git clone -b Thesis https://github.com/YuiZh0u/TextGAN-PyTorch.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJWHBqMSDFD3"
   },
   "source": [
    "## Instalación de requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGJm75BcCMDt",
    "outputId": "f0994661-7aad-4510-fc57-8aa6df8d3eff"
   },
   "outputs": [],
   "source": [
    "!cd TextGAN-PyTorch && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5hx8DyiCfRu"
   },
   "outputs": [],
   "source": [
    "!apt-get install libboost-all-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install build-essential cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOWD0lNvBaQp"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/kpu/kenlm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EySEq8gCqcy"
   },
   "outputs": [],
   "source": [
    "!cd kenlm && mkdir -p build && cd build && cmake .. && make -j 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_NVZl9AaA8ve",
    "outputId": "6b4dc1ec-435a-48ff-f51e-5877c3c58187"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jfrez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AUcuCCxa1NXj"
   },
   "outputs": [],
   "source": [
    "# !cp /content/gdrive/MyDrive/word2vec/covid_tweets_equal16.txt /content/gdrive/MyDrive/TextGAN-PyTorch/dataset/testdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "from IPython.core import magic_arguments\n",
    "from IPython.core.magic import Magics, cell_magic, magics_class\n",
    "from IPython.utils.capture import CapturedIO\n",
    "\n",
    "\n",
    "class Tee(StringIO):\n",
    "    def __init__(self, initial_value='', newline='\\n', stream=None):\n",
    "        self.stream = stream\n",
    "        super().__init__(initial_value, newline)\n",
    "    \n",
    "    def write(self, data):\n",
    "        if self.stream is not None:\n",
    "            self.stream.write(data)\n",
    "        \n",
    "        super().write(data)\n",
    "\n",
    "\n",
    "class capture_and_print_output(object):\n",
    "    stdout = True\n",
    "    stderr = True\n",
    "    display = True\n",
    "    \n",
    "    def __init__(self, stdout=True, stderr=True, display=True):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "        self.display = display\n",
    "        self.shell = None\n",
    "    \n",
    "    def __enter__(self):\n",
    "        from IPython.core.getipython import get_ipython\n",
    "        from IPython.core.displaypub import CapturingDisplayPublisher\n",
    "        from IPython.core.displayhook import CapturingDisplayHook\n",
    "        \n",
    "        self.sys_stdout = sys.stdout\n",
    "        self.sys_stderr = sys.stderr\n",
    "        \n",
    "        if self.display:\n",
    "            self.shell = get_ipython()\n",
    "            if self.shell is None:\n",
    "                self.save_display_pub = None\n",
    "                self.display = False\n",
    "        \n",
    "        stdout = stderr = outputs = None\n",
    "        if self.stdout:\n",
    "            stdout = sys.stdout = Tee(stream=sys.stdout)\n",
    "        if self.stderr:\n",
    "            stderr = sys.stderr = Tee(stream=sys.stderr)\n",
    "        if self.display:\n",
    "            self.save_display_pub = self.shell.display_pub\n",
    "            self.shell.display_pub = CapturingDisplayPublisher()\n",
    "            outputs = self.shell.display_pub.outputs\n",
    "            self.save_display_hook = sys.displayhook\n",
    "            sys.displayhook = CapturingDisplayHook(shell=self.shell,\n",
    "                                                   outputs=outputs)\n",
    "        \n",
    "        return CapturedIO(stdout, stderr, outputs)\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.sys_stdout\n",
    "        sys.stderr = self.sys_stderr\n",
    "        if self.display and self.shell:\n",
    "            self.shell.display_pub = self.save_display_pub\n",
    "            sys.displayhook = self.save_display_hook\n",
    "\n",
    "\n",
    "@magics_class\n",
    "class CustomMagics(Magics):\n",
    "    @magic_arguments.magic_arguments()\n",
    "    @magic_arguments.argument('output', type=str, default='', nargs='?')\n",
    "    @magic_arguments.argument('--no-stderr', action='store_true')\n",
    "    @magic_arguments.argument('--no-stdout', action='store_true')\n",
    "    @magic_arguments.argument('--no-display', action='store_true')\n",
    "    @cell_magic\n",
    "    def tee(self, line, cell):\n",
    "        args = magic_arguments.parse_argstring(self.tee, line)\n",
    "        out = not args.no_stdout\n",
    "        err = not args.no_stderr\n",
    "        disp = not args.no_display\n",
    "        with capture_and_print_output(out, err, disp) as io:\n",
    "            self.shell.run_cell(cell)\n",
    "        if args.output:\n",
    "            self.shell.user_ns[args.output] = io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_id: 3, gpu_id: 0\n",
      "====================================================================================================\n",
      "> training arguments:\n",
      ">>> if_test: 0\n",
      ">>> run_model: seqgan\n",
      ">>> k_label: 2\n",
      ">>> dataset: covid_tweets\n",
      ">>> model_type: vanilla\n",
      ">>> loss_type: rsgan\n",
      ">>> mu_type: ragan\n",
      ">>> eval_type: Ra\n",
      ">>> d_type: Ra\n",
      ">>> if_real_data: 1\n",
      ">>> cuda: 1\n",
      ">>> device: 0\n",
      ">>> devices: 0\n",
      ">>> shuffle: 0\n",
      ">>> gen_init: normal\n",
      ">>> dis_init: uniform\n",
      ">>> n_parent: 1\n",
      ">>> eval_b_num: 8\n",
      ">>> lambda_fq: 1.0\n",
      ">>> lambda_fd: 0.0\n",
      ">>> d_out_mean: True\n",
      ">>> freeze_dis: False\n",
      ">>> freeze_clas: False\n",
      ">>> use_all_real_fake: False\n",
      ">>> use_population: False\n",
      ">>> samples_num: 10000\n",
      ">>> vocab_size: 29329\n",
      ">>> mle_epoch: 5\n",
      ">>> clas_pre_epoch: 10\n",
      ">>> adv_epoch: 3\n",
      ">>> inter_epoch: 15\n",
      ">>> batch_size: 64\n",
      ">>> max_seq_len: 66\n",
      ">>> start_letter: 1\n",
      ">>> padding_idx: 0\n",
      ">>> gen_lr: 0.01\n",
      ">>> gen_adv_lr: 0.0001\n",
      ">>> dis_lr: 0.0001\n",
      ">>> clip_norm: 5.0\n",
      ">>> pre_log_step: 10\n",
      ">>> adv_log_step: 1\n",
      ">>> train_data: dataset/covid_tweets.txt\n",
      ">>> test_data: dataset/testdata/covid_tweets_test.txt\n",
      ">>> temp_adpt: exp\n",
      ">>> evo_temp_step: 1\n",
      ">>> temperature: 1\n",
      ">>> ora_pretrain: 1\n",
      ">>> gen_pretrain: 0\n",
      ">>> dis_pretrain: 0\n",
      ">>> adv_g_step: 1\n",
      ">>> rollout_num: 16\n",
      ">>> gen_embed_dim: 32\n",
      ">>> gen_hidden_dim: 32\n",
      ">>> goal_size: 16\n",
      ">>> step_size: 4\n",
      ">>> mem_slots: 1\n",
      ">>> num_heads: 2\n",
      ">>> head_size: 256\n",
      ">>> d_step: 5\n",
      ">>> d_epoch: 3\n",
      ">>> adv_d_step: 6\n",
      ">>> adv_d_epoch: 2\n",
      ">>> dis_embed_dim: 64\n",
      ">>> dis_hidden_dim: 64\n",
      ">>> num_rep: 64\n",
      ">>> use_nll_oracle: 1\n",
      ">>> use_nll_gen: 1\n",
      ">>> use_nll_div: 1\n",
      ">>> use_bleu: 1\n",
      ">>> use_self_bleu: 1\n",
      ">>> use_clas_acc: True\n",
      ">>> use_ppl: 0\n",
      ">>> log_file: log/log_1124_1731_11.txt\n",
      ">>> save_root: save/20211124/covid_tweets/seqgan_vanilla_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl66_temp1_lfd0.0_T1124_1731_11/\n",
      ">>> signal_file: run_signal.txt\n",
      ">>> tips: SeqGAN experiments\n",
      "====================================================================================================\n",
      "GenDataIter prepare samples:  tensor([[18867,  1643,  5784,  ...,     0,     0,     0],\n",
      "        [12623,  4611, 10783,  ...,     0,     0,     0],\n",
      "        [11197, 17954, 24688,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1649, 14246, 15919,  ...,     0,     0,     0],\n",
      "        [28187,  3422,  2957,  ...,     0,     0,     0],\n",
      "        [ 9627, 10022,  5197,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare samples size:  torch.Size([100000, 66])\n",
      "GenDataIter prepare inp:  tensor([[    1, 18867,  1643,  ...,     0,     0,     0],\n",
      "        [    1, 12623,  4611,  ...,     0,     0,     0],\n",
      "        [    1, 11197, 17954,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  1649, 14246,  ...,     0,     0,     0],\n",
      "        [    1, 28187,  3422,  ...,     0,     0,     0],\n",
      "        [    1,  9627, 10022,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare inp size:  torch.Size([100000, 66])\n",
      "GenDataIter prepare target:  tensor([[18867,  1643,  5784,  ...,     0,     0,     0],\n",
      "        [12623,  4611, 10783,  ...,     0,     0,     0],\n",
      "        [11197, 17954, 24688,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1649, 14246, 15919,  ...,     0,     0,     0],\n",
      "        [28187,  3422,  2957,  ...,     0,     0,     0],\n",
      "        [ 9627, 10022,  5197,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare target size:  torch.Size([100000, 66])\n",
      "GenDataIter prepare samples:  tensor([[24562, 20042, 14384,  ...,     0,     0,     0],\n",
      "        [28187, 12702,  8815,  ...,     0,     0,     0],\n",
      "        [ 1835, 17266, 11133,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1609, 26557, 24722,  ...,     0,     0,     0],\n",
      "        [23244,  2099, 19708,  ...,     0,     0,     0],\n",
      "        [28187, 25622, 20797,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare samples size:  torch.Size([1000, 66])\n",
      "GenDataIter prepare inp:  tensor([[    1, 24562, 20042,  ...,     0,     0,     0],\n",
      "        [    1, 28187, 12702,  ...,     0,     0,     0],\n",
      "        [    1,  1835, 17266,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  1609, 26557,  ...,     0,     0,     0],\n",
      "        [    1, 23244,  2099,  ...,     0,     0,     0],\n",
      "        [    1, 28187, 25622,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare inp size:  torch.Size([1000, 66])\n",
      "GenDataIter prepare target:  tensor([[24562, 20042, 14384,  ...,     0,     0,     0],\n",
      "        [28187, 12702,  8815,  ...,     0,     0,     0],\n",
      "        [ 1835, 17266, 11133,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1609, 26557, 24722,  ...,     0,     0,     0],\n",
      "        [23244,  2099, 19708,  ...,     0,     0,     0],\n",
      "        [28187, 25622, 20797,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare target size:  torch.Size([1000, 66])\n",
      "Starting Generator MLE Training...\n",
      "generator.py sample: (num_samples) 10000\n",
      "generator.py sample: (batch_size) 256\n",
      "generator.py sample: (num_batch) 40\n",
      "generator.py sample: (samples) tensor([[17578,  3616, 13222,  ...,     0,     0,     0],\n",
      "        [20673, 27429, 22792,  ...,     0,     0,     0],\n",
      "        [ 6842,  4572, 26557,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [10876, 27429,  4135,  ...,     0,     0,     0],\n",
      "        [    0,  4577, 12145,  ...,     0,     0,     0],\n",
      "        [24722, 24718, 10503,  ...,     0,     0,     0]])\n",
      "generator.py sample: (samples size) torch.Size([10000, 66])\n",
      "GenDataIter prepare samples:  tensor([[17578,  3616, 13222,  ...,     0,     0,     0],\n",
      "        [20673, 27429, 22792,  ...,     0,     0,     0],\n",
      "        [ 6842,  4572, 26557,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [10876, 27429,  4135,  ...,     0,     0,     0],\n",
      "        [    0,  4577, 12145,  ...,     0,     0,     0],\n",
      "        [24722, 24718, 10503,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare samples size:  torch.Size([10000, 66])\n",
      "GenDataIter prepare inp:  tensor([[    1, 17578,  3616,  ...,     0,     0,     0],\n",
      "        [    1, 20673, 27429,  ...,     0,     0,     0],\n",
      "        [    1,  6842,  4572,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1, 10876, 27429,  ...,     0,     0,     0],\n",
      "        [    1,     0,  4577,  ...,     0,     0,     0],\n",
      "        [    1, 24722, 24718,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare inp size:  torch.Size([10000, 66])\n",
      "GenDataIter prepare target:  tensor([[17578,  3616, 13222,  ...,     0,     0,     0],\n",
      "        [20673, 27429, 22792,  ...,     0,     0,     0],\n",
      "        [ 6842,  4572, 26557,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [10876, 27429,  4135,  ...,     0,     0,     0],\n",
      "        [    0,  4577, 12145,  ...,     0,     0,     0],\n",
      "        [24722, 24718, 10503,  ...,     0,     0,     0]])\n",
      "GenDataIter prepare target size:  torch.Size([10000, 66])\n",
      "generator.py sample: (num_samples) 200\n",
      "generator.py sample: (batch_size) 200\n",
      "generator.py sample: (num_batch) 1\n",
      "generator.py sample: (samples) tensor([[ 2855,  7347, 14006,  ...,     0,     0,     0],\n",
      "        [14006, 26004,  4572,  ...,     0,     0,     0],\n",
      "        [ 1649, 26557, 11400,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [18065, 17029,  4998,  ...,     0,     0,     0],\n",
      "        [10488, 16807, 21983,  ...,     0,     0,     0],\n",
      "        [18065,  7707,  4082,  ...,     0,     0,     0]])\n",
      "generator.py sample: (samples size) torch.Size([200, 66])\n"
     ]
    }
   ],
   "source": [
    "%%tee output\n",
    "!cd TextGAN-PyTorch/run && python3 run_seqgan.py 3 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%tee output\n",
    "# !cd TextGAN-PyTorch/run && python3 run_catgan.py 6 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "filename = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "with open('outputs_pynb/output{}.txt'.format(filename), 'w') as f:\n",
    "    f.write(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('output08.txt', 'w') as f:\n",
    "#     f.write(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"hola\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd TextGAN-PyTorch/utils && python3 visualization-Copy1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Discrete GANs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
